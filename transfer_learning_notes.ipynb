{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6abb588-798c-42af-9cf3-98dc0dbcd2af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Transfer Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf0fc2c-3f85-4f09-8ffd-5b194b0af1e7",
   "metadata": {},
   "source": [
    "## Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc8431-57d4-4601-9850-823edc068005",
   "metadata": {},
   "source": [
    "Since we are conducting transfer learning there were a few items that needed to be completed in order to get the model to work with the current dataset.\n",
    "\n",
    "- First\n",
    "    - We call in the model by invoking hub.KerasLayer with a link to it in the zoo\n",
    "- Second\n",
    "    - Our images do not have the correct input size so we needed to reshape with padding in order to not distort the images\n",
    "- Third\n",
    "    - Our model requires us to use images with 3 channels so we had to use greyscale_to_rgb function available in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5c657f-baee-451c-bef2-dc1ce60c1872",
   "metadata": {},
   "source": [
    "## Initial Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63650a53-8c2a-4b98-beeb-ae2d569f3e45",
   "metadata": {},
   "source": [
    "using efficientnetv2-b0 : https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2 for our model and conducting transfer learning, we froze the upper layers intially"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f0d3f-5c6b-4b52-83d3-ed2f9b7d6f7d",
   "metadata": {},
   "source": [
    "#### Original Setup\n",
    "\n",
    "<img src=\"model_arc.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca0fd5-0ecb-4d11-9300-241b79f1a18a",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19d38df-c7c9-472f-981f-dcf5b19eb89c",
   "metadata": {},
   "source": [
    "Initial Parameters:\n",
    "- batch size: 120=8\n",
    "- epochs: 10\n",
    "- tf.keras.regularizers.l2(0.0001))\n",
    "- tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)\n",
    "- tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38a499-a01e-419e-af6c-5789dc821250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: \"sequential\"\n",
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# keras_layer (KerasLayer)     (None, 1280)              5919312   \n",
    "# _________________________________________________________________\n",
    "# dropout (Dropout)            (None, 1280)              0         \n",
    "# _________________________________________________________________\n",
    "# dense (Dense)                (None, 4)                 5124      \n",
    "# =================================================================\n",
    "# Total params: 5,924,436\n",
    "# Trainable params: 5,124\n",
    "# Non-trainable params: 5,919,312\n",
    "# _________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d460c-58b9-4142-bfc7-a48e1c3e5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 144/144 [==============================] - 6s 35ms/step - loss: 0.9730 - accuracy: 0.6191\n",
    "# Train loss: 0.9729554057121277\n",
    "# Train accuracy: 0.619140625\n",
    "# 17/17 [==============================] - 2s 47ms/step - loss: 1.0249 - accuracy: 0.5614\n",
    "# validation loss: 1.02485990524292\n",
    "# validation accuracy: 0.5614035129547119\n",
    "# 40/40 [==============================] - 2s 45ms/step - loss: 1.0307 - accuracy: 0.5637\n",
    "# Test loss: 1.0306953191757202\n",
    "# Test accuracy: 0.5637216567993164"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a92921-1c96-49e4-92c3-b54af16949a7",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e04aa2-66f1-4f4c-82b4-0544f9906971",
   "metadata": {},
   "source": [
    "Tried to increase epochs but that did not do much to model accuracy. The model stopped learning after the 15th epoch. Going to try to lower batch size and see what occurs. Lowering batch size did not do much to increase the accuracy. Going to try to use a different optimizers with the current setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71effaf-1edf-41ba-bd48-9dc6520eff93",
   "metadata": {},
   "source": [
    "When we switched the Adam optimizer it increased test accuracy by 3%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dffbab-bf5f-4733-9303-bf29ec8adcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 144/144 [==============================] - 6s 36ms/step - loss: 0.8980 - accuracy: 0.6793\n",
    "# Train loss: 0.8980469107627869\n",
    "# Train accuracy: 0.6792534589767456\n",
    "# 17/17 [==============================] - 1s 34ms/step - loss: 0.9113 - accuracy: 0.6784\n",
    "# validation loss: 0.9113450646400452\n",
    "# validation accuracy: 0.6783625483512878\n",
    "# 40/40 [==============================] - 1s 36ms/step - loss: 1.0105 - accuracy: 0.5934\n",
    "# Test loss: 1.0104659795761108\n",
    "# Test accuracy: 0.5934323668479919"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17051947-e048-4342-a150-865f5587ca3a",
   "metadata": {},
   "source": [
    "The current network setup is the same as before but the batch size and epochs are 20 and 64. Going to increase epochs by an extreme amount to 100. The test accuracy increased by 3% to 62% but we do not think 100 epochs are necessary. Through testing we find that 60 epochs are necessary for achieving this accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c91f73b-f10f-4c54-b2bb-df814a5174f1",
   "metadata": {},
   "source": [
    "We decided to add a datagenerator in order to extend the current dataset which will augment the images within the batch randomly. Adding this data generator, we found, lowered the accuracy intially, so we decided to tweak with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed29ad-fa4e-4076-a65b-f4b4751fd556",
   "metadata": {},
   "source": [
    "Before tweaking the data generator, we decided to unfreeze the model because we froze the previous layers besides the final ouput layer. This increased accuracy to 64.7%, but there was much more overfitting. We then decided to test the data generator in order to reduce this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08f66b3-5857-46a8-a5ca-fa9106f618e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 144/144 [==============================] - 7s 35ms/step - loss: 0.5382 - accuracy: 0.9010\n",
    "# Train loss: 0.538211464881897\n",
    "# Train accuracy: 0.9010416865348816\n",
    "# 17/17 [==============================] - 3s 48ms/step - loss: 0.6544 - accuracy: 0.8460\n",
    "# validation loss: 0.6543669104576111\n",
    "# validation accuracy: 0.8460038900375366\n",
    "# 40/40 [==============================] - 2s 45ms/step - loss: 1.0864 - accuracy: 0.6474\n",
    "# Test loss: 1.0863642692565918\n",
    "# Test accuracy: 0.6473807692527771"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2098ea-5c3f-43cd-9d3a-80033a17eb4d",
   "metadata": {},
   "source": [
    "We added the following to the data generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b279256c-cdce-4517-8f51-ebf30b9b5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "   horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "        # Randomly translate the images horizontally and vertically\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "\n",
    "    # Randomly apply shearing transformations\n",
    "    shear_range=0.1,\n",
    "\n",
    "    # Randomly zoom in and out on the images\n",
    "    zoom_range=0.1\n",
    ")\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85530e7-30b4-414b-8c8d-b09c62a86645",
   "metadata": {},
   "source": [
    "- Besides of having only horizontal_flip, vertical_flip, and fill_mode, we added everything past that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee22410-1763-4d42-ba6b-c247f0ab1c6c",
   "metadata": {},
   "source": [
    "This created a model of accuracy 67%. There is still a decent amount of overfitting ocurring, but that is bound to happen with a small dataset as the brain scans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af231be-ad27-4955-8b33-c6e1ecf82ba1",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b80c52-cf54-4a64-80c5-6f25a35c30fd",
   "metadata": {},
   "source": [
    "After numerous testing we determined the best model to be of original architecture from the tensorflow hub where we switched out the final output layer for our number of classes. We also determined that Adam optimization was a much better optimizer than the original SGD. We also learned that using a datagenerator helped decrease overfitting and forced the model to learn actual features. In the end we ended with a model of 67% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb8feae-78ae-4376-9b3a-c0d1d83005f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow +GPU",
   "language": "python",
   "name": "python3-tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
