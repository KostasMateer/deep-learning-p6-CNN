{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35563b5c-a57d-4575-a446-29638563129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import History\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import brainscanfunctions as funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "417f18ab-a3c5-442f-b331-99922b0e54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_directory = \"/home/DAVIDSON/brwiedenbeck/public/brain_scans/test\"\n",
    "train_directory = \"/home/DAVIDSON/brwiedenbeck/public/brain_scans/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70dc47f6-b9e2-4dec-a3bb-bbd5e62569ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, counts_test = funcs.load_brain_scan(test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "223f3c79-9c78-4a66-b67f-05ccaae4d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, counts_train = funcs.load_brain_scan(train_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "295b7b88-999c-4111-9c82-76e139bb469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe126f84-334d-458b-bfac-48289653c057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[448, 640, 12, 179]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4a7bf84-585e-4aeb-943f-fcce6b8ea7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1792, 2560, 52, 717]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ce00b8-8922-4bd2-8232-6c2d5ed4ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2240 3200 64 896 = 6400 test is 25% of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7bbc156-a3b1-4421-8f72-b6027d7e854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 208\n",
    "img_cols = 176\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abd19a63-a488-4ef1-906f-887988de674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_val = X_val.astype('float32')\n",
    "X_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa4caeff-7931-480f-b57b-54da57416993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1279"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "701926a1-27fb-431c-b109-28114d25ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dba6390-bfae-4350-8aa4-22b360f14879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fabec2c-8b1e-4712-946d-4e4a149141f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "   horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9274a1d6-4106-4d5e-9a65-e21a25bfac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "654526e5-1d4a-4f6a-beb2-628ba2609668",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_classes = 4\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d157781-2e91-4eb1-a8e1-a8ec961cb8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 70, 59, 256)       20992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 7, 256)         5308672   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               230500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 5,560,568\n",
      "Trainable params: 5,560,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=(9,9), strides=(3,3),\n",
    "                        padding=\"same\", activation='relu',\n",
    "                        input_shape=input_shape))\n",
    "model.add(layers.MaxPooling2D(pool_size=(3,3), padding='same'))\n",
    "# model.add(layers.Dropout(.5))\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=(9,9), strides=(3,3),\n",
    "                        padding=\"same\", activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(3,3), padding='same'))\n",
    "# model.add(layers.Dropout(.5))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "# model.add(layers.Dropout(.5))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc90632f-d57c-46f5-8f0d-129bd79d9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['categorical_accuracy', 'accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd45d00b-4d16-4b17-8685-b510d3f4087f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 4s 80ms/step - loss: 1.1048 - categorical_accuracy: 0.4937 - accuracy: 0.4937\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 4s 78ms/step - loss: 1.0346 - categorical_accuracy: 0.5020 - accuracy: 0.5020\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 4s 78ms/step - loss: 1.0078 - categorical_accuracy: 0.5052 - accuracy: 0.5052\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 4s 78ms/step - loss: 0.9426 - categorical_accuracy: 0.5428 - accuracy: 0.5428\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 4s 78ms/step - loss: 0.9047 - categorical_accuracy: 0.5727 - accuracy: 0.5727\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 4s 78ms/step - loss: 0.8685 - categorical_accuracy: 0.5849 - accuracy: 0.5849\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 4s 80ms/step - loss: 0.8433 - categorical_accuracy: 0.6094 - accuracy: 0.6094\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 4s 78ms/step - loss: 0.8136 - categorical_accuracy: 0.6248 - accuracy: 0.6248\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 4s 78ms/step - loss: 0.7565 - categorical_accuracy: 0.6560 - accuracy: 0.6560\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 4s 78ms/step - loss: 0.7089 - categorical_accuracy: 0.6851 - accuracy: 0.6851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14c4a9741760>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = History()\n",
    "model.fit(train_datagen.flow(X_train, y_train,\n",
    "                             batch_size=batch_size),\n",
    "          # x=X_train,\n",
    "          # y=y_train,\n",
    "          #batch_size=batch_size,\n",
    "          #class_weight=class_weights,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=[history]\n",
    "          # class_weight = {0:1, 1:1, 2:2, 3:1}\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad8c626b-fb3d-4891-a7a3-b28502c930ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 11ms/step - loss: 0.7055 - categorical_accuracy: 0.6678 - accuracy: 0.6678\n",
      "Train loss: 0.7054663896560669\n",
      "Train accuracy: 0.6677517294883728\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.7405 - categorical_accuracy: 0.6413 - accuracy: 0.6413\n",
      "validation loss: 0.740510880947113\n",
      "validation accuracy: 0.6413255333900452\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose=1)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', train_score[1])\n",
    "val_score = model.evaluate(X_val, y_val, verbose=1)\n",
    "print('validation loss:', val_score[0])\n",
    "print('validation accuracy:', val_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cacd937-c1fa-47f4-94aa-94acb4b14b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 12ms/step - loss: 0.9691 - categorical_accuracy: 0.5684 - accuracy: 0.5684\n",
      "Test loss: 0.9691101908683777\n",
      "Test accuracy: 0.5684128403663635\n"
     ]
    }
   ],
   "source": [
    "test_score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a0464-213b-4113-b493-b688d6b16359",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed51522b-d83d-40e0-9f5e-5f68b66376f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8427986-677f-4207-ae6b-0ae4e0a32c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"graphs1.jpg\")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"graphs2.jpg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c8e3c-d7a5-4055-bc99-16d63731cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee2d8b3-cbd3-435e-a23f-73e5f2ff224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_weights(class_series, multi_class=True, one_hot_encoded=False):\n",
    "  \"\"\"\n",
    "  Method to generate class weights given a set of multi-class or multi-label labels, both one-hot-encoded or not.\n",
    "  Some examples of different formats of class_series and their outputs are:\n",
    "    - generate_class_weights(['mango', 'lemon', 'banana', 'mango'], multi_class=True, one_hot_encoded=False)\n",
    "    {'banana': 1.3333333333333333, 'lemon': 1.3333333333333333, 'mango': 0.6666666666666666}\n",
    "    - generate_class_weights([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]], multi_class=True, one_hot_encoded=True)\n",
    "    {0: 0.6666666666666666, 1: 1.3333333333333333, 2: 1.3333333333333333}\n",
    "    - generate_class_weights([['mango', 'lemon'], ['mango'], ['lemon', 'banana'], ['lemon']], multi_class=False, one_hot_encoded=False)\n",
    "    {'banana': 1.3333333333333333, 'lemon': 0.4444444444444444, 'mango': 0.6666666666666666}\n",
    "    - generate_class_weights([[0, 1, 1], [0, 0, 1], [1, 1, 0], [0, 1, 0]], multi_class=False, one_hot_encoded=True)\n",
    "    {0: 1.3333333333333333, 1: 0.4444444444444444, 2: 0.6666666666666666}\n",
    "  The output is a dictionary in the format { class_label: class_weight }. In case the input is one hot encoded, the class_label would be index\n",
    "  of appareance of the label when the dataset was processed. \n",
    "  In multi_class this is np.unique(class_series) and in multi-label np.unique(np.concatenate(class_series)).\n",
    "  Author: Angel Igareta (angel@igareta.com)\n",
    "  \"\"\"\n",
    "  if multi_class:\n",
    "    # If class is one hot encoded, transform to categorical labels to use compute_class_weight   \n",
    "    if one_hot_encoded:\n",
    "      class_series = np.argmax(class_series, axis=1)\n",
    "  \n",
    "    # Compute class weights with sklearn method\n",
    "    class_labels = np.unique(class_series)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=class_labels, y=class_series)\n",
    "    return dict(zip(class_labels, class_weights))\n",
    "  else:\n",
    "    # It is neccessary that the multi-label values are one-hot encoded\n",
    "    mlb = None\n",
    "    if not one_hot_encoded:\n",
    "      mlb = MultiLabelBinarizer()\n",
    "      class_series = mlb.fit_transform(class_series)\n",
    "\n",
    "    n_samples = len(class_series)\n",
    "    n_classes = len(class_series[0])\n",
    "\n",
    "    # Count each class frequency\n",
    "    class_count = [0] * n_classes\n",
    "    for classes in class_series:\n",
    "        for index in range(n_classes):\n",
    "            if classes[index] != 0:\n",
    "                class_count[index] += 1\n",
    "    \n",
    "    # Compute class weights using balanced method\n",
    "    class_weights = [n_samples / (n_classes * freq) if freq > 0 else 1 for freq in class_count]\n",
    "    class_labels = range(len(class_weights)) if mlb is None else mlb.classes_\n",
    "    return dict(zip(class_labels, class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9affd-870b-46e9-a383-43a6587c8685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = generate_class_weights(y_train, one_hot_encoded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3fe240-6bc8-4950-a409-6437f99bb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7329ba4-ae67-4050-8cf1-abdfce3679a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e31d327-1832-4060-b540-5378e7ddc2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467950e-3871-4ec3-9df4-da0a84194efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3be25-11da-4e44-bda6-1c47e5cec01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s = np.concatenate((y_train,y_test, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241cb679-72f8-4ac5-9112-1c5abac8af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c416f81-9455-4c4a-9246-96afbbf9136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = generate_class_weights(y_s, one_hot_encoded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec39ee-2c09-4566-8b86-a46db7f0dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a93d79-0213-4613-8755-0e9ad608a9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow +GPU",
   "language": "python",
   "name": "python3-tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
